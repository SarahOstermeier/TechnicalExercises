{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwBodRP9IIfXVihpFmiGXo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarahOstermeier/TechnicalExercises/blob/main/Arize_Technical_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Planning\n",
        "\n",
        "**Objective:**  Build a RAG application\n",
        "\n",
        "## Approach\n",
        "\n",
        "**Format:** Jupyter Notebook (Google Colab)  \n",
        "**Stretch Goal:** Optimize performance (primary), Build UX (secondary)  \n",
        "**Framework:** Langchain or DSPy  \n",
        "**LLM Provider:** Huggingface or Mistral  \n",
        "**Dataset:** [OpenStax](https://openstax.org/subjects)\n",
        "\n",
        "****\n",
        "\n",
        "## Requirements\n",
        "\n",
        "**A working RAG app with some interface for Q&A**  \n",
        "* ~75-80% of the time, 2-3 hours <br>\n",
        "\n",
        "\n",
        "**Thorough documentation**  \n",
        "\n",
        "* Clear setup instructions - make it so anyone can follow in your footsteps\n",
        "* Tell us why you picked your tools\n",
        "* Share what worked, what didn't, and how you dealt with it\n",
        "* What would you do next if you had more time?\n",
        "* ~20-25% of your time, 1 hour\n",
        "\n",
        "****\n",
        "\n",
        "## Tips\n",
        "\n",
        "* Use those quickstart tools - no need to reinvent the wheel\n",
        "* Document as you go - future you will thank you\n",
        "* LLMs are your friend here, donâ€™t be afraid to use them to help, just be sure you take the time to really understand what they tell you.\n",
        "* Hit a wall? Don't spin your wheels - reach out!\n",
        "* Keep it focused - better to nail the basics than half-finish three extra features"
      ],
      "metadata": {
        "id": "rnvVjlbV2yqp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to run this notebook"
      ],
      "metadata": {
        "id": "i8JPcqF0NNeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My process\n",
        "\n",
        "## Planning\n",
        "\n",
        "### Appraoch and Tools\n",
        "* I decided to work in Google Colab since it is a tool I am familiar with and will allow me to get started quickly without much setup.\n",
        "* As my RAG framework I chose DSPy, as I'm interested interested in trying out DSPy Optimizers and thought this would be a good opportunity to do so.  \n",
        "* Related to the above, my stretch goal is to optimize performance.\n",
        "* I'll be using HuggingFace or Mistral as my LLM provider, as I already have accounts for both and can access easily.\n",
        "\n",
        "### Use Case and Dataset Selection\n",
        "I started a project on Claude and provided the exercise instructions and the Jupyter Notebook I started as project content. I used Claude to brainstorm project ideas and related datasets and eventually decided to build a RAG tool to query textbooks, using documents from [OpenStax](https://openstax.org/subjects) as my dataset.\n",
        "\n",
        "## Implementation\n",
        "*italicized text*"
      ],
      "metadata": {
        "id": "6y57z-iJJnGR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment set up"
      ],
      "metadata": {
        "id": "C3Xx0TJmNVba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install relevant libraries\n",
        "\n",
        "[**DSPy**](https://dspy.ai/)\n",
        "\n",
        "DSPy provides a \"prompts as code\" library, enabling AI developers to standardize, modularize, and optimize their AI applicatins.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6ctR71kIIQ-M"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lTJAiGhMJlu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N_Wg8RL-NZ-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model set up\n",
        "In this tutorial I'll be accessing models thorugh [Mistral](https://mistral.ai/) and through Huggingface's ([ Serverless inference API](https://huggingface.co/docs/api-inference/index), both of which can be used for free, with some limitiations. The API calls will be made through **DSPy**, which [integrates with a wide range of model providers](https://dspy.ai/)"
      ],
      "metadata": {
        "id": "oKbOyMZv6xRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Model provider API keys as environment variables."
      ],
      "metadata": {
        "id": "u7DV1JoRyFOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comment out if API keys are not saved in your google colab userdata\n",
        "from google.colab import userdata\n",
        "os.environ[\"MISTRAL_API_KEY\"] = userdata.get('MISTRAL_API_KEY')\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = userdata.get('HUGGINGFACE_API_KEY')\n",
        "\n",
        "## Uncomment and add API keys here if they are not saved in your google colab userdata\n",
        "# os.environ[\"MISTRAL_API_KEY\"] = 'YOUR_MISTRAL_API_KEY'\n",
        "# os.environ[\"HUGGINGFACE_API_KEY\"] = 'YOUR_HUGGINGFACE_API_KEY"
      ],
      "metadata": {
        "id": "4kcTkbYOyCR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access the LLM endpoint with with DSPy."
      ],
      "metadata": {
        "id": "Vx78m6CH5W1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dspy\n",
        "\n",
        "lm = dspy.LM('mistral/mistral-small-latest', api_key=os.environ[\"MISTRAL_API_KEY\"])\n",
        "dspy.configure(lm=lm)"
      ],
      "metadata": {
        "id": "s4zfgXMJ29W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the endpoint.\n"
      ],
      "metadata": {
        "id": "BNvZE-3J3dvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lm(messages=[{\"role\": \"user\", \"content\": \"Say this is a test!\"}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiyaMttr3iqZ",
        "outputId": "a115075e-72d1-400b-db88-8714ca920e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"This is a test! How can I assist you today? Let's make sure everything is working perfectly.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "oFWlcKaFOCkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection and Processing"
      ],
      "metadata": {
        "id": "k-NRMdl7OH_v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DSPy Setup for RAG"
      ],
      "metadata": {
        "id": "dzJGctgKOlqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Educational Domain Knowledge"
      ],
      "metadata": {
        "id": "xRM11j4wOwwC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "URVVfXD2O7EW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM Usage Disclosure\n",
        "\n",
        "The following LLM-based assistants were used in the development of this notebook:\n",
        "\n",
        "Claude 3.7 Sonnet for:\n",
        "* Use case brainstorming and dataset selection\n",
        "\n",
        "\n",
        "\n",
        "## Authorship\n",
        "All core components, concepts, and technical implementation of this notebook were authored by Sarah Ostermeier. LLM assistance was limited to the specific tasks listed above.\n"
      ],
      "metadata": {
        "id": "KdZzVVlDL0m4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFKdBWE62KB7"
      },
      "outputs": [],
      "source": []
    }
  ]
}